{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install shutup\n",
        "import shutup\n",
        "shutup.please()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL6v-5ZufKkz",
        "outputId": "1461f0d1-e0d8-40b2-a2cf-d73b2587b8d7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shutup\n",
            "  Downloading shutup-0.2.0-py3-none-any.whl (1.5 kB)\n",
            "Installing collected packages: shutup\n",
            "Successfully installed shutup-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCDAFwjhads2"
      },
      "source": [
        "### Test random enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O7-RQ-XLads6"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW88DgxPads9"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "states = env.observation_space.shape[0]\n",
        "actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVbMAVhTads_",
        "outputId": "7f75917d-7a87-4e99-8984-e2fee08112d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1, reward: 31.0\n",
            "Episode: 2, reward: 12.0\n",
            "Episode: 3, reward: 19.0\n",
            "Episode: 4, reward: 24.0\n",
            "Episode: 5, reward: 13.0\n",
            "Episode: 6, reward: 13.0\n",
            "Episode: 7, reward: 32.0\n",
            "Episode: 8, reward: 11.0\n",
            "Episode: 9, reward: 35.0\n",
            "Episode: 10, reward: 14.0\n",
            "Episode: 11, reward: 10.0\n",
            "Episode: 12, reward: 20.0\n",
            "Episode: 13, reward: 32.0\n",
            "Episode: 14, reward: 42.0\n",
            "Episode: 15, reward: 15.0\n"
          ]
        }
      ],
      "source": [
        "episodes = 15\n",
        "for episode in range(1, episodes + 1):\n",
        "    state = env.reset()\n",
        "    score = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = random.choice([0,1])\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "\n",
        "    print(f\"Episode: {episode}, reward: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z0ANQX6adtB"
      },
      "source": [
        "### Create a deep learning model with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JCkwOxxzadtC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers.legacy import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_B_KS90adtD"
      },
      "outputs": [],
      "source": [
        "def build_model(states, actions):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(1, states)))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcVl4dzzadtF",
        "outputId": "3de991ea-a452-4352-d4cf-3845887d2d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 24)                120       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 770 (3.01 KB)\n",
            "Trainable params: 770 (3.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(states, actions)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3MUMKYYadtH"
      },
      "source": [
        "### Build agent with Keras-RL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iG5FWsbOadtP"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from keras import __version__\n",
        "tensorflow.keras.__version__ = __version__\n",
        "\n",
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import  SequentialMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSjtFfU5adtS"
      },
      "outputs": [],
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = BoltzmannQPolicy()\n",
        "    memory = SequentialMemory(limit=50000, window_length=1)\n",
        "    agent = DQNAgent(policy=policy, model=model, memory=memory,\n",
        "                     nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "dqn.fit(env, nb_steps=50000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yigzpZgcSsW",
        "outputId": "b71cbbdb-ea1d-48dd-a5a9-6ec7b81e5a61"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "10000/10000 [==============================] - 97s 10ms/step - reward: 1.0000\n",
            "50 episodes - episode_reward: 198.180 [152.000, 200.000] - loss: 10.235 - mae: 43.137 - mean_q: 86.769\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 100s 10ms/step - reward: 1.0000\n",
            "54 episodes - episode_reward: 184.685 [82.000, 200.000] - loss: 13.234 - mae: 42.871 - mean_q: 86.020\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 111s 11ms/step - reward: 1.0000\n",
            "51 episodes - episode_reward: 196.000 [47.000, 200.000] - loss: 10.103 - mae: 41.393 - mean_q: 83.237\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 1.0000\n",
            "51 episodes - episode_reward: 197.725 [102.000, 200.000] - loss: 10.500 - mae: 42.831 - mean_q: 85.955\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 116s 12ms/step - reward: 1.0000\n",
            "done, took 523.014 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e39a860d300>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = dqn.test(env, nb_episodes=100, visualize=False)"
      ],
      "metadata": {
        "id": "bWfPIkoDeZId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visual = dqn.test(env, nb_episodes=15, visualize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZtp3bP4ho1T",
        "outputId": "f84d76d4-febb-4fea-ce75-7fc479e2b9bf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 15 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save"
      ],
      "metadata": {
        "id": "bL0xUJxsiZJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.save_weights(\"dqn_weights.h5f\", overwrite=True)"
      ],
      "metadata": {
        "id": "111cig-LiYff"
      },
      "execution_count": 56,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}